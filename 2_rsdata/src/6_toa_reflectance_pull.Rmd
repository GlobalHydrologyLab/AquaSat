---
title: "06_toa_matchups"
output: html_document
editor_options: 
  chunk_output_type: console
---
#Pull toa reflectance values associated with in situ samples.

This script is essentially the same as script 5_surface_reflectance_pull.Rmd but utilizes the top-of atmosphere Landsat collections instead of surface reflectance.  See script 5 for further detail. 

```{r setup, include=FALSE}
library(tidyverse)
library(feather)
library(knitr)
library(purrr)
library(reticulate)
library(googledrive)
opts_knit$set(root.dir='../..')

```

#Retrieve existing data to avoid duplicating reflectance pulls

```{r Get Existing}

##Download in-situ sites and dates
splits <- drive_ls('watersat/2_rsdata/out/split_wide/')

##546 is the number of split_wide files as of 04/11/18, this may need to be changed if the wqp/lagos data changes.

if(length(list.files('2_rsdata/out/split_wide')) < 546){
  for(i in 1:nrow(splits)) {
    path = paste0(getwd(),'/2_rsdata/out/split_wide/', splits$name[i])
    drive_download(as_id(splits$id[i]),
                   path=path, overwrite = TRUE)
  }
}



```

#Open a python bash script to interact with Google Earth Engine using the package reticulate.

```{r Google Earth Engine Pull}

filesDownR <- drive_ls("watersat/2_rsdata/out/toa_matchups/") %>% 
  select(name)

#Set .RProfile to set the default python for reticulate
Sys.setenv(RETICULATE_PYTHON = '/usr/local/bin/python2')

##repl_python basically starts a python bash window within your R chunk.  This can be used to actually interact with earth engine.
repl_python()

import time
import ee
import os
import feather
ee.Initialize()

#Source necessary functions.
execfile('2_rsdata/src/5a_6a_GEE_pull_functions.py')

#Load in Pekel water occurance Layer and Landsat Collections.

pekel = ee.Image('JRC/GSW1_0/GlobalSurfaceWater')

l8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_TOA')
l7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_TOA')
l5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_TOA').map(addPan)

#Identify collection for use in sourced functions.
collection = 'TOA'

#Standardize band names between the various collections and aggregate 
#them into one image collection

bn8 = ['B2','B3', 'B4', 'B5', 'B6','B7', 'B8', 'BQA']
bn57 = ['B1', 'B2', 'B3', 'B4', 'B5','B7', 'B8', 'BQA']
bns = ['Blue', 'Green', 'Red', 'Nir', 'Swir1', 'Swir2', 'Pan', 'qa']
  
ls5 = l5.select(bn57, bns)
ls7 = l7.select(bn57, bns)
ls8 = l8.select(bn8, bns)

ls = ee.ImageCollection(ls5.merge(ls7).merge(ls8))

#Selct the occurence layer in the pekel mask, which is just the 
#percentage of water occurence over a given pixel from 1985-2015.
#Set the percent occurance threshold and create a watermask from the result.
threshold = 80
water = pekel.select('occurrence').gt(threshold)
water = water.updateMask(water)

#Set buffer distance of pixels to include in median and standard deviation #calculation.  Distance is in meters from supplied sample point.  
dist = 120

#Identify folder with in-situ data broken up into 5000 observation chunks by path/row and
ULdir = '2_rsdata/out/split_wide/'

#Generate file lists for both files to be sent and files already processed in google earth engine
filesDown = r.filesDownR['name']
filesUp = os.listdir(ULdir) 

#Remove hidden formatting file in directory and any file names in filesUp that are already in files down.
filesUp  = filter(lambda x: x  != '.DS_Store', filesUp)
filesDown = [i.replace(".csv", ".feather") for i in filesDown]

filesUpFlt = [x for x in filesUp if x not in filesDown]


#### Wrap it all up in a for loop running through our list of files

for x in range(0,len(filesUpFlt)):

  #Read in our file as a feather data frame
  inv = feather.read_dataframe(ULdir + filesUpFlt[x])
  #turn our inventory into a feature collection by assigning 
  #lat longs and a site id.  Do this via list comprehension 
  #(similar to for loop but faster and apparently plays nice with earth engine.)
  invOut = ee.FeatureCollection([ee.Feature(ee.Geometry.Point([inv['long'][i],\
  inv['lat'][i]]),{'SiteID':inv['SiteID'][i],  'date':inv['date'][i],'date_unity':inv['date_unity'][i]}) for i in range(0,len(inv))]) 
  
  #Pull out the path/row from the file name
  path = int(filesUpFlt[x].replace('.','_').split('_')[0])
  row = int(filesUpFlt[x].replace('.','_').split('_')[1])
  
  #Filter image collection to path/row  
  lsover = ee.ImageCollection(ls.filter(ee.Filter.eq('WRS_PATH',\
  path)).filter(ee.Filter.eq('WRS_ROW', row)))
    
  ## Map over sites within specific path row and pull reflectance values
  data = ee.FeatureCollection(invOut.map(sitePull))
  
  #Extract path/row count Variable so names match up with file sent to GGE
  if filesUpFlt[x].replace('.','_').split('_')[2] == 'feather':
    count = ''
  else:
    count = '_'+str(int(filesUpFlt[x].replace('.','_').split('_')[2]))
  
  #Create queue of tasks to export to earth engine
  dataOut = ee.batch.Export.table.toDrive(collection = data, \
                                              description = str(path)\
                                               +'_'+str(row) + count,\
                                              folder = 'WQP_TOA_MatchUps',\
                                              fileFormat = 'csv')
  #Check how many existing tasks are running and take a break if it's >15
  maximum_no_of_tasks(15, 60)
  #Send next task.
  dataOut.start()

#Make sure all Earth engine tasks are completed prior to moving on.  
maximum_no_of_tasks(1,300)
print('done')

## End the python bash.
exit
```

#Update local repository

```{r Update Repositories}
  
#Finally, download the new data locally.

filesNew <- drive_ls('WQP_TOA_MatchUps')

for(i in 1:nrow(filesNew)) {
  path = paste0(getwd(),'/2_rsdata/out/toa_matchups/', filesNew$name[i])
  drive_download(as_id(filesNew$id[i]),
                 path=path, overwrite = TRUE)
}

# Move files from personal folder into team folder. This should leave the team folder #up-to-date and the personal folder empty to avoid duplicates for future pulls.
for(i in 1:nrow(filesNew)) {
  drive_mv(as_id(filesNew$id[i]), path = 'watersat/2_rsdata/out/toa_matchups/')
}

```

